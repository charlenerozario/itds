{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLS Regression - Simple Train and Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notbook Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set working directory\n",
    "os.chdir(\".\")\n",
    "\n",
    "# make sure it is set right\n",
    "print(os.getcwd())\n",
    "\n",
    "# make sure plots display in notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weekly marketing spend (in thousand's) by channel and the corresponding product sales (in million's)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the advertising data set\n",
    "ad_df = pd.read_csv(\"http://www-bcf.usc.edu/~gareth/ISL/Advertising.csv\", index_col = [0])\n",
    "\n",
    "# look at the top rows\n",
    "ad_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# describe the dataset\n",
    "ad_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the data types\n",
    "ad_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(ad_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(ad_df[\"sales\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(ad_df.drop(columns = \"sales\").corr(), annot=True, cmap=\"YlGnBu\", square = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training - Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifying the regression model\n",
    "ols_m1 = linear_model.LinearRegression()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# feature set\n",
    "X = ad_df.drop(columns = \"sales\")\n",
    "\n",
    "# target\n",
    "y = ad_df[\"sales\"]\n",
    "\n",
    "# creating training / testings datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X_train))\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the regression model\n",
    "ols_m1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assumption Checking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Errors should be independently and identically normally distributed with a mean of 0 and a fixed variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residuals vs. Fitted Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# residuals versus fitted values\n",
    "def plot_fit(fitted_values, residuals):\n",
    "    plt.scatter(fitted_values, residuals)\n",
    "    plt.axhline(y = 0, color = \"r\")\n",
    "    plt.xlabel(\"Fitted Values\")\n",
    "    plt.ylabel(\"Residuals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = ols_m1.predict(X_train) - y_train\n",
    "\n",
    "fitted_values = ols_m1.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call\n",
    "plot_fit(fitted_values, residuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of Residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of residuals\n",
    "def plot_residuals(residuals):\n",
    "    residuals.name = \"Residuals\"\n",
    "    sns.distplot(residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call\n",
    "plot_residuals(residuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training - Model 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove High Influence Point?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[residuals != residuals.max()]\n",
    "\n",
    "y_train = y_train[residuals != residuals.max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifying the regression model\n",
    "ols_m2 = linear_model.LinearRegression()\n",
    "\n",
    "# fit the regression model\n",
    "ols_m2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assumption Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = ols_m2.predict(X_train) - y_train\n",
    "\n",
    "fitted_values = ols_m2.predict(X_train)\n",
    "\n",
    "plot_fit(fitted_values, residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_residuals(residuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use statsmodels\n",
    "olssm_m2 = sm.OLS(y_train, X_train).fit()\n",
    "\n",
    "# print summary\n",
    "olssm_m2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training - Model 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Newspaper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_clean = X_train.drop(columns = [\"newspaper\"])\n",
    "X_test_clean = X_test.drop(columns = [\"newspaper\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifying the regression model\n",
    "ols_m3 = linear_model.LinearRegression()\n",
    "\n",
    "# fit the regression model\n",
    "ols_m3.fit(X_train_clean,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assumption Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = ols_m3.predict(X_train_clean) - y_train\n",
    "\n",
    "fitted_values = ols_m3.predict(X_train_clean)\n",
    "\n",
    "plot_fit(fitted_values, residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_residuals(residuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for estimate in zip(X_train.columns, ols_m1.coef_):\n",
    "     print(\"Fit 1 estimate: \", estimate)\n",
    "\n",
    "for estimate in zip(X_train.columns, ols_m2.coef_):\n",
    "     print(\"Fit 2 estimate: \", estimate)\n",
    "        \n",
    "for estimate in zip(X_train_clean.columns, ols_m3.coef_):\n",
    "     print(\"Fit 3 estimate: \", estimate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intercept?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ols_m1.intercept_)\n",
    "print(ols_m2.intercept_)\n",
    "print(ols_m3.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted\n",
    "predicted_m1 = ols_m1.predict(X_test)\n",
    "predicted_m2 = ols_m2.predict(X_test)\n",
    "predicted_m3 = ols_m3.predict(X_test_clean)\n",
    "\n",
    "# actual\n",
    "validate = pd.DataFrame(y_test)\n",
    "\n",
    "validate.columns = ['actual']\n",
    "\n",
    "validate['m1'] = predicted_m1\n",
    "validate['m2'] = predicted_m2\n",
    "validate['m3'] = predicted_m3\n",
    "\n",
    "validate.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean squared error\n",
    "def mse(df, model):\n",
    "    mse = np.sum((validate['actual'] - validate[model])**2) / len(validate)\n",
    "    print(\"The \" + model + \" Mean Squared Error is \" + str(mse))\n",
    "    \n",
    "models = [\"m1\", \"m2\", \"m3\"]\n",
    "\n",
    "for model in models:\n",
    "    mse(validate, model)\n",
    "\n",
    "# sklearn mse\n",
    "# mean_squared_error(predicted, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you spot any ways to improve the model? Is the OLS linear model appropriate here? Why do you think the R-squared value actually gets worse in model 2? Hint: Check the assumptions!!!\n",
    "What about p-values???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data sourced from An Introduction to Statistical Learning\n",
    "with Applications in R\n",
    "Gareth James, Daniela Witten, Trevor Hastie and Robert Tibshirani."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
